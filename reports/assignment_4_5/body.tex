\textit{This brief report explains how we constructed the intermediate representation for the $\mu$C programming language and generated the concluding LLVM-assembler.}

\section{Intermediate Representation}

%TODO How is our IR represented? Structure etc.
Our intermediate representation (IR) is essentially a flattened out version of our abstract syntax tree (AST).
All nodes in the original AST have been converted into ordered flat instructions that can later be directly translated into Low Level Virtual Machine (LLVM) instructions. Thus our IR is very similar to that of LLVM.

%TODO How is the IR generated?
The IR is generated by calling "generate\_ir" on the root node of the AST. This method takes a list as one of its arguments, which is the list that all IR instructions are then appended to by the consecutive walk down the AST. All nodes know how to append themselves to this list, but before they do they have to call "generate\_ir" on their children to ensure that they are evaluated before themselves to ensure correct order of the instructions.

%TODO Describe a simple IR-tree. Tikz picture?
As an example, we take the example $\mu$C-code in listing \ref{lst:example_c} and generate the IR for it. The generated IR is then similar (not verbatim copy) to listing \ref{lst:example_ir}.

\lstinputlisting[float, label=lst:example_c, caption={
  Example program in $\mu$C.
}]{example.c}

\lstinputlisting[float, label=lst:example_ir, caption={
  Example program in listing \ref{lst:example_c} converted to a simplified version of our IR.
}]{example.ir}

As can be seen in listing \ref{lst:example_ir}, we have a global variable with the name "i" and the type "i32", then we have a function named "main". The function in our IR has five parameters, the first being the name of the function, the second represents the type, the third is a list of formals, the fourth is a list of local declarations in the function, and the fifth and last one is a list of all statements in the function.

The statement list contains two statements, the first being an Eval instruction that takes an identifier as first argument and an expression as second argument. The identifier refers to the global variable "i", and the expression is simply a constant i32 value, namely $1$.

The second statement is a return instruction, which takes an expression or identifier as argument. Here we return the value of the identifier "i".

\section{Code Generation}

%TODO How is the LLVM code generated out of the IR structure?
After the IR has been constructed, converting this to proper LLVM-assembly is very straightforward. Because our IR is so close to LLVM already each instruction can be translated straight to LLVM-assembly without any further pre-processing.

%TODO  - Walking down the IR-tree etc.
Generating the LLVM-assembly is similar to generating the IR. Iterate over the IR-list constructed from the AST and call "generate\_llvm" on each entry. Each call to this method returns a string that represents the LLVM-assembly for that particular instruction. Then concatenate all strings together to form the complete program.

\subsection{LLVM Structure}

%TODO What is the general layout of LLVM code?
The structure of the LLVM assembly language is very close to ordinary assembly with the exception of some high-level functionality such as strict typing and functions.

%TODO How does it compare to assembler such as MIPS?

%TODO What are the benefits of using LLVM instead of MIPS?
Some of the benefits gained by outputting LLVM-assembly instead of MIPS-assembly is that the compiler is able to target a wide range of hardware that can be targeted using LLVM; instead of only being bound to a single instruction set architecture. It will also be able to leverage the tremendous work put into the LLVM framework on generating highly optimized code.

\subsection{Control Flow Statements}

% FROM ASSIGNMENT:
%TODO how control flow statements are translated

$\mu$C has two kind of statements for control flow, while statements and if statements. During compilation these statements are translated into labels and branches.

While statements are translated into two basic blocks. The first contains the computation of the condition and branching based on the condition. The second contains the body of the while statement.

If statements are translated into two or three parts, depending on if it has an else part or not. The first part contains the computation of the condition and branching based on the condition. The second part contains the then-block of the if statement. The last part contains the else-block, if the if statement has an else part. In our compiler blocks need to be wrapped in curly brackets, except for an else followed immediately by a new if statement. The new if statement will be the else-body.

Listing \ref{lst:while_ll} and \ref{lst:if_ll} show the llvm code generated by our compiler for programs in listing \ref{lst:while_c} and \ref{lst:if_c}.



\lstinputlisting[float, label=lst:while_c, caption={
  Example program with while statement in $\mu$C.
}]{while.c}

\lstinputlisting[float, label=lst:while_ll, caption={
  Program in listing \ref{lst:while_c} compiled to llvm.
  The function "main" begins by allocating space for an integer 32 bits in size on the stack.
  It then unconditionally jumps into the "while\_start1" block. This block contains the condition check of the while-loop.
  Inside this block it first loads the value store in the previously allocated memory space (which at the first iteration would contain whatever value was already on the stack when the memory was allocated by the function).
  After the load is completed it compares the loaded value to zero. This results in a single bit true or false value, stored under temporary "\%2".
  It then performs a conditional branch based on the truth value. If the value is true it jumps to the "while\_body2" block, else it jumps to the "while\_end3" block.
  Inside the "while\_body2" block it stores the value 42 into the allocated space
  Then it jumps back to the "while\_start1" block to perform the condition check again.
  When the "while\_end3" block is reached the loop has terminated and the function returns zero to the caller.
}]{while.ll}

\lstinputlisting[float, label=lst:if_c, caption={
  Example program with else-if statement in $\mu$C.
}]{if.c}

\lstinputlisting[float, label=lst:if_ll, caption={
  Program in listing \ref{lst:if_c} compiled to llvm.
  It begins by allocating memory on the stack and stores a pointer to it under the local variable "i".
  It then performs a conditional branch to either block "if\_then1" or "if\_else2".
  Inside block "if\_then1" it stores the value $1$ to "i". It then branches to the "if\_end3" block.
  In "if\_else2" it branches to "if\_then4" if $1 == 0$, otherwise it branches to "if\_else5".
  The two blocks "if\_then4" and "if\_else5" are almost equivalent, they store a value to "i" then jumps to "if\_end6".
  The only thing "if\_end6" does is branch to the "if\_end3" block which marks the end of the outer if-statement.
}]{if.ll}

% Other notes:
%TODO How do we handle if-statements?
%TODO How do we handle while-statements?
%TODO What is the structure of these in IR and LLVM?
%TODO Basic blocks?

\subsection{Variable References}

% FROM ASSIGNMENT:
%TODO how variable references are translated, and how you handle the difference between local and global variables, and the difference between scalar and array variables
Variables are read using load instructions and written to using store instructions. This is similar to regular assembly, but not in the way you allocate them.
Allocating a local variable on the stack in functions is analogous to how one would allocate memory on the heap in C or similar languages.

An example of stack allocation and usage of local variables in LLVM can be seen in listing \ref{lst:example_stack_allocation}.

\lstinputlisting[float, label=lst:example_stack_allocation, caption={
  Example of stack allocation and usage of local variables in LLVM-assembly. The function "foo" contains a single allocation of an integer with the size of 32 bits. It then stores a value in the allocated space, loads it, and returns the value stored in it. On line four in the example it loads the value of the local variable into a temporary, and then returns that value on line five.
}]{stack_allocation.ll}

% Local vs global variables
A global variable is never allocated on the stack, thus its initialization is different from local variables. In LLVM-assembly they are also annotated differently from local variables and temporaries.
An example of a global allocation that is equivalent to listing \ref{lst:example_stack_allocation} can be seen in listing \ref{lst:example_global_allocation}.

\lstinputlisting[float, label=lst:example_global_allocation, caption={
  Example of global allocation and usage in LLVM-assembly. The code is equivalent to listing \ref{lst:example_stack_allocation}.
}]{global_allocation.ll}

% Scalar vs array variables
The difference in allocation between scalar variables and arrays in LLVM is miniscule. The only difference being is the type specified when defining them. An example of both a scalar variable and an array definition in LLVM can be seen in listing \ref{lst:scalar_array}.

%In order to access elements inside arrays you first have to calculate a pointer to that element using a call to "getelementptr". When you have the pointer you can access it just as you access a scalar in LLVM.
To access the elements of an array, a call to "getelementptr" has to be made. This call takes a reference to the array, an offset, and an index. It then returns a pointer to the element at that index and offset in the given array which can then be used as a regular variable is used in LLVM.

When arrays are passed as arguments to functions, the array reference is converted to a raw pointer. The raw pointer is then passed function and used to access the memory of the array.

\lstinputlisting[float, label=lst:scalar_array, caption={
  Example of stack allocation of a variable and an array in LLVM. The equivalent $\mu$C-code can be seen in the comments in the example.
}]{scalar_array.ll}

% Other notes:
%TODO How are arrays passed in function calls?
%TODO How do we access array-elements? Store, load etc
%TODO Temporaries and their counters

\section{Design Decisions}

%TODO made the IR similar to LLVM to simplify translation
We made our intermediate representation consciously similar to the expected output of the LLVM-assembly in order to simplify the translation from IR to LLVM. By doing this, the number of IR-instructions is almost identical to the number of LLVM-instructions produced in the final result.

%TODO Our solution to putint, putstring etc. Where we include a header in the LLVM code if needed.
When compiling a program that relies on the builtin "putint", "putstring", "getint", etc. functions the compiler will auto-insert a header into the generated LLVM-assembly. This header contains the pre-compiled assembly for the builtin functions required. This is because the functions rely on C-syntax that our compiler is not able to compile, such as pointers and variable arguments. This could have posed an issue if LLVM had not been as high level as it is. Some basic testing has shown that this header compiles to the same assembly on different machines running different versions of LLVM.

%TODO How do we handle the creation of new basic blocks in LLVM after a return?
%TODO Name of the output file and how it is handled using temp files etc.

% - Semi-decisions, should we really describe these in this section?
%TODO How do we flatten arithmetic expressions? Are there any design decisions there?
%TODO How do we handle references to global variables inside functions? How do we determine if it is referencing a local or global?

\section{Usage}
%TODO How do you use the compiler?

The compiler can be used from the command line. The following instruction will assume that the \texttt{bin/} directory is in your path. The compiler expects a $\mu$C file as input and will generate an executable binary file.

The following example will compile and link \texttt{fib.c} into \texttt{fib}:
\begin{lstlisting}[language=bash,numbers=none]
    $\$$ ucc fib.c
\end{lstlisting}

It is also possible to specify the name of the output file. Use the following command to name the output file \texttt{fibonacci}:
\begin{lstlisting}[language=bash,numbers=none]
    $\$$ ucc -o fibonacci fib.c
\end{lstlisting}

The compiler can also emit both llvm and asm files. Use \texttt{--emit-llvm} to emit llvm and \texttt{--emit-asm} to emit asm. See the following example:
\begin{lstlisting}[language=bash,numbers=none]
    $\$$ ucc fib.c --emit-llvm --emit-asm
\end{lstlisting}

Use \texttt{-h} or \texttt{--help} flags for more options.

%TODO What are the generated output files?
%TODO How do you execute the generated .ll files?
%TODO How do you generate a binary out of the .ll files?

\section{Future Work}

A more robust solution to our pre-compiled header would have been to replace the pre-compiled assembly with code our compiler could actually handle. Unfortunately we were not able to succeed in doing that. Which is why we chose the more "unstable" solution. This could be solved if given more time. A possible solution would be to actually add support for pointers and variable arguments to the compiler allowing it to compile the C-code required to use the builtin functions.

%TODO Is there anything we could have improved if given more time?
%TODO What could be improved?

%TODO Can the compiler be used to cross-compile?
Since our compiler is outputting LLVM-assembly it is possible for it to compile code for a different architecture than the one it is running on. We have not currently added support for defining the target architecture to the compiler, but that is something that could easily be implemented since it is nothing that requires any work on our part.

\section{Conclusions}

Designing and implementing IR and code generation was difficult. Neither of us had any prior experience with LLVM and did not anticipate the impact some of our previous decisions would have.

Even though this was the most challenging part of the compiler, it was also the most rewarding one and the feeling of being able to compile and run real programs with our compiler was incredible.

Our compiler is far from perfect. Unfortunately, time compelled us to cut corners and there are parts of the implementation that we are not happy with.

However, the journey from nothing to a working compiler has taught us a lot and we truly hope future students will get the opportunity to take this course and experience the amazing feeling of compiling and running real programs with their own compilers.


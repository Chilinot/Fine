\textit{This brief report explains how we constructed the intermediate representation for the $\mu$C programming language and generated the concluding LLVM-assembler.}

\section{Intermediate Representation}

%TODO How is our IR represented? Structure etc.
Our intermediate representation (IR) is essentially a flattened out version of our abstract syntax tree (AST).
All nodes in the original AST have been converted into ordered flat instructions that can later be directly translated into Low Level Virtual Machine (LLVM) instructions. Thus our IR is very similar to that of LLVM.

%TODO How is the IR generated?
The IR is generated by calling "generate\_ir" on the root node of the AST. This method takes a list as one of its arguments, which is the list that all IR instructions are then appended to by the consecutive walk down the AST. All nodes know how to append themselves to this list, but before they do they have to call "generate\_ir" on their children to ensure that they are evaluated before themselves to ensure correct order of the instructions.

%TODO Describe a simple IR-tree. Tikz picture?
As an example, we take the example $\mu$C-code in listing \ref{lst:example_c} and generate the IR for it. The generated IR is then similar (not verbatim copy) to listing \ref{lst:example_ir}.

\lstinputlisting[float, label=lst:example_c, caption={
  Example program in $\mu$C.
}]{example.c}

\lstinputlisting[float, label=lst:example_ir, caption={
  Example program in listing \ref{lst:example_c} converted to a simplified version of our IR.
}]{example.ir}

As can be seen in listing \ref{lst:example_ir}, we have a global variable with the name "i" and the type "i32", then we have a function named "main". The function in our IR has five parameters, the first being the name of the function, the second represents the type, the third is a list of formals, the fourth is a list of local declarations in the function, and the fifth and last one is a list of all statements in the function.

The statement list contains two statements, the first being an Eval instruction that takes an identifier as first argument and an expression as second argument. The identifier refers to the global variable "i", and the expression is simply a constant i32 value, namely $1$.

The second statement is a return instruction, which takes an expression or identifier as argument. Here we return the value of the identifier "i".

\section{Code Generation}

%TODO How is the LLVM code generated out of the IR structure?
After the IR has been constructed, converting this to proper LLVM-assembly is very straightforward. Because our IR is so close to LLVM already each instruction can be translated straight to LLVM-assembly without any further pre-processing.

%TODO  - Walking down the IR-tree etc.
Generating the LLVM-assembly is similar to generating the IR. Iterate over the IR-list constructed from the AST and call "generate\_llvm" on each entry. Each call to this method returns a string that represents the LLVM-assembly for that particular instruction. Then concatenate all strings together to form the complete program.

\subsection{LLVM Structure}

%TODO What is the general layout of LLVM code?
The structure of the LLVM assembly language is very close to ordinary assembly with the exception of some high-level functionality such as strict typing and functions.

%TODO How does it compare to assembler such as MIPS?

%TODO What are the benefits of using LLVM instead of MIPS?
Some of the benefits gained by outputting LLVM-assembly instead of MIPS-assembly is that the compiler is able to target a wide range of hardware that can be targeted using LLVM; instead of only being bound to a single instruction set architecture. It will also be able to leverage the tremendous work put into the LLVM framework on generating highly optimized code.

\subsection{Control Flow Statements}

% FROM ASSIGNMENT:
%TODO how control flow statements are translated

% Other notes:
%TODO How do we handle if-statements?
%TODO How do we handle while-statements?
%TODO What is the structure of these in IR and LLVM?
%TODO Basic blocks?

\subsection{Variable References}

% FROM ASSIGNMENT:
%TODO how variable references are translated, and how you handle the difference between local and global variables, and the difference between scalar and array variables
Variables are read using load instructions and written to using store instructions. This is similar to regular assembly, but not in the way you allocate them.
Allocating a local variable on the stack in functions is analogous to how one would allocate memory on the heap in C or similar languages.

An example of stack allocation and usage of local variables in LLVM can be seen in listing \ref{lst:example_stack_allocation}.

\lstinputlisting[float, label=lst:example_stack_allocation, caption={
  Example of stack allocation and usage of local variables in LLVM-assembly. The function "foo" contains a single allocation of an integer with the size of 32 bits. It then stores a value in the allocated space, loads it, and returns the value stored in it. On line four in the example it loads the value of the local variable into a temporary, and then returns that value on line five.
}]{stack_allocation.ll}

% Local vs global variables
A global variable is never allocated on the stack, thus its initialization is different from local variables. In LLVM-assembly they are also annotated differently from local variables and temporaries.
An example of a global allocation that is equivalent to listing \ref{lst:example_stack_allocation} can be seen in listing \ref{lst:example_global_allocation}.

\lstinputlisting[float, label=lst:example_global_allocation, caption={
  Example of global allocation and usage in LLVM-assembly. The code is equivalent to listing \ref{lst:example_stack_allocation}.
}]{global_allocation.ll}

% Scalar vs array variables
The difference in allocation between scalar variables and arrays in LLVM is miniscule. The only difference being is the type specified when defining them. An example of both a scalar variable and an array definition in LLVM can be seen in listing \ref{lst:scalar_array}.

%In order to access elements inside arrays you first have to calculate a pointer to that element using a call to "getelementptr". When you have the pointer you can access it just as you access a scalar in LLVM.
To access the elements of an array, a call to "getelementptr" has to be made. This call takes a reference to the array, an offset, and an index. It then returns a pointer to the element at that index and offset in the given array which can be used as a regular variable is used in LLVM.

\lstinputlisting[float, label=lst:scalar_array, caption={
  Example of stack allocation of a variable and an array in LLVM. The equivalent $\mu$C-code can be seen in the comments in the example.
}]{scalar_array.ll}

%TODO if you map temporaries to registers, and if so, how

% Other notes:
%TODO Stack allocations
%TODO Global allocations
%TODO Arrays?
%TODO How are arrays passed in function calls?
%TODO How do we access regular allocations, store, load etc.
%TODO How do we access array-elements? Store, load etc
%TODO Temporaries and their counters

\section{Design Decisions}

%TODO Our solution to putint, putstring etc. Where we include a header in the LLVM code if needed.
%TODO How do we handle the creation of new basic blocks in LLVM after a return?
%TODO Name of the output file and how it is handled using temp files etc.

% - Semi-decisions, should we really describe these in this section?
%TODO How do we flatten arithmetic expressions? Are there any design decisions there?
%TODO How do we handle references to global variables inside functions? How do we determine if it is referencing a local or global?

\section{Usage}
%TODO How do you use the compiler?
%TODO What are the generated output files?
%TODO How do you execute the generated .ll files?
%TODO How do you generate a binary out of the .ll files?

\section{Future Work}
%TODO Is there anything we could have improved if given more time?
%TODO What could be improved?
%TODO Can the compiler be used to cross-compile?

\section{Conclusions}
